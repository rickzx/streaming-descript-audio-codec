{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non stream: <torch.utils.benchmark.utils.common.Measurement object at 0x177ccb010>\n",
      "wn_conv1d(data)\n",
      "  4.72 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "Cached: <torch.utils.benchmark.utils.common.Measurement object at 0x2883e9190>\n",
      "wn_conv1d_cached(data)\n",
      "  4.75 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "False\n",
      "tensor([[[ 0.2391,  0.2759,  0.8915,  ...,  2.2475,  1.3730,  2.1704],\n",
      "         [ 0.5690,  0.3283,  0.4935,  ...,  0.8048,  0.7730,  0.4228],\n",
      "         [-2.4467,  0.4928, -3.4065,  ..., -1.7856, -1.5958, -0.1326],\n",
      "         ...,\n",
      "         [-2.7717, -0.6683, -1.0477,  ..., -0.8070, -1.1878, -0.1473],\n",
      "         [ 0.9553,  0.9808,  0.7493,  ...,  0.8611,  1.7939,  1.8238],\n",
      "         [ 0.8837,  0.9023,  1.0396,  ...,  1.5872,  0.4577,  1.1960]],\n",
      "\n",
      "        [[ 0.7317,  2.8882,  1.5236,  ...,  3.4878,  4.8952,  0.2520],\n",
      "         [ 0.4875,  0.8073,  0.5325,  ...,  0.0925, -0.2831,  0.4675],\n",
      "         [-1.6555, -2.3700, -6.8651,  ..., -0.8240, -1.1611,  0.9850],\n",
      "         ...,\n",
      "         [-2.3175,  0.3974, -1.1541,  ..., -2.0387, -2.5608, -2.1537],\n",
      "         [ 0.1785,  0.1062,  0.9603,  ...,  1.4923,  0.2642,  1.1658],\n",
      "         [ 0.6244,  0.9748,  0.4891,  ...,  1.1547,  2.0384,  0.3623]],\n",
      "\n",
      "        [[ 1.5471,  2.3142, -0.0321,  ...,  3.3907,  1.0151,  1.6523],\n",
      "         [ 0.4586,  0.5339,  0.6181,  ...,  0.4847,  0.4774,  0.2738],\n",
      "         [ 0.5580, -4.5806, -4.2872,  ..., -0.5131, -1.7315, -2.7107],\n",
      "         ...,\n",
      "         [-1.8273, -0.8208, -2.4517,  ..., -0.5116, -1.3388, -0.9865],\n",
      "         [ 1.8638,  1.4054,  0.8197,  ...,  0.4049,  1.1175,  1.8428],\n",
      "         [ 1.2679,  0.9172,  0.3428,  ...,  1.0127,  0.9199,  0.7257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4303,  0.9407,  2.3502,  ...,  3.3942,  0.6659,  2.2038],\n",
      "         [ 0.8776,  0.6746,  0.8299,  ...,  0.5432,  0.0854,  0.9620],\n",
      "         [-1.5673, -2.2818, -1.1140,  ..., -0.3446, -3.4646,  2.6042],\n",
      "         ...,\n",
      "         [-0.9756,  0.7678, -1.0456,  ..., -1.2936, -1.6903, -0.6169],\n",
      "         [ 0.3488,  0.2618,  0.7301,  ...,  1.3557,  0.4638,  1.2840],\n",
      "         [ 1.2235,  0.1695,  1.3875,  ...,  1.1901,  0.7750,  0.7964]],\n",
      "\n",
      "        [[-0.4298,  3.1034,  0.5441,  ..., -1.2649,  0.4618,  1.4332],\n",
      "         [ 0.7998,  0.5493,  0.3957,  ...,  0.2120,  0.3455,  0.5838],\n",
      "         [-6.2248, -3.5599,  2.3173,  ...,  0.8402, -2.2254, -5.6610],\n",
      "         ...,\n",
      "         [-1.3530, -1.3505, -0.2200,  ..., -4.3648, -1.3759, -1.9862],\n",
      "         [ 0.5831,  0.0352,  1.0047,  ...,  1.7583,  1.3935,  0.4970],\n",
      "         [ 0.1642,  0.5625,  0.8667,  ...,  1.3045,  0.6640,  0.9124]],\n",
      "\n",
      "        [[ 1.1173, -0.5701,  2.2973,  ...,  1.5074, -0.0987, -0.0401],\n",
      "         [ 0.1803,  0.1208,  0.0668,  ...,  0.4868,  1.0641,  0.4058],\n",
      "         [-0.4448, -3.3007, -3.5659,  ...,  1.1532, -2.6787, -2.4315],\n",
      "         ...,\n",
      "         [-0.8209, -2.2548, -2.2953,  ..., -1.5619, -0.6384, -0.8196],\n",
      "         [ 1.5494,  0.4939,  0.9105,  ...,  0.5522,  0.8653,  1.0681],\n",
      "         [ 1.4491,  0.6100,  1.2613,  ...,  1.6963,  0.3467,  1.1721]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[[ 0.2825, -0.5846,  1.5126,  ...,  2.2475,  1.3730,  2.1704],\n",
      "         [ 0.4864,  0.3958,  0.3485,  ...,  0.8048,  0.7730,  0.4228],\n",
      "         [-2.9725, -0.4101, -4.5392,  ..., -1.7856, -1.5958, -0.1326],\n",
      "         ...,\n",
      "         [-2.3340, -0.7670, -1.2040,  ..., -0.8070, -1.1878, -0.1473],\n",
      "         [ 0.6933,  1.7488,  0.4465,  ...,  0.8611,  1.7939,  1.8238],\n",
      "         [ 0.8814,  0.9317,  1.0783,  ...,  1.5872,  0.4577,  1.1960]],\n",
      "\n",
      "        [[ 1.7714,  4.4648,  2.0478,  ...,  3.4878,  4.8952,  0.2520],\n",
      "         [ 0.3898,  0.4867,  0.4420,  ...,  0.0925, -0.2831,  0.4675],\n",
      "         [-3.8468, -1.3138, -5.7110,  ..., -0.8240, -1.1610,  0.9850],\n",
      "         ...,\n",
      "         [-3.2091,  0.0291, -1.2403,  ..., -2.0387, -2.5608, -2.1537],\n",
      "         [ 0.2386, -0.0411,  0.8886,  ...,  1.4923,  0.2642,  1.1658],\n",
      "         [ 0.2171,  0.9279,  0.5288,  ...,  1.1547,  2.0384,  0.3623]],\n",
      "\n",
      "        [[ 2.7223,  1.9528,  0.6128,  ...,  3.3907,  1.0151,  1.6523],\n",
      "         [ 0.4105,  0.4822,  0.4169,  ...,  0.4847,  0.4774,  0.2738],\n",
      "         [ 0.6733, -5.7016, -4.5761,  ..., -0.5131, -1.7315, -2.7107],\n",
      "         ...,\n",
      "         [-2.2669, -0.9687, -2.5095,  ..., -0.5116, -1.3388, -0.9865],\n",
      "         [ 1.4375,  2.3988,  0.6742,  ...,  0.4049,  1.1175,  1.8428],\n",
      "         [ 1.4224,  0.5305,  0.2056,  ...,  1.0127,  0.9199,  0.7257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0084,  1.1182,  1.7579,  ...,  3.3942,  0.6659,  2.2038],\n",
      "         [ 1.3705,  0.6062,  1.0218,  ...,  0.5432,  0.0854,  0.9620],\n",
      "         [-0.9218, -1.7391, -0.9112,  ..., -0.3446, -3.4646,  2.6042],\n",
      "         ...,\n",
      "         [-0.2387,  0.8064, -0.9721,  ..., -1.2936, -1.6903, -0.6169],\n",
      "         [ 0.8621, -0.3459,  0.8296,  ...,  1.3557,  0.4638,  1.2840],\n",
      "         [ 0.9570,  0.2876,  1.5078,  ...,  1.1901,  0.7750,  0.7964]],\n",
      "\n",
      "        [[-0.2200,  2.5865, -0.0236,  ..., -1.2649,  0.4618,  1.4332],\n",
      "         [ 0.6284,  0.5614,  0.5135,  ...,  0.2120,  0.3455,  0.5838],\n",
      "         [-5.1870, -3.0487,  2.7328,  ...,  0.8402, -2.2254, -5.6610],\n",
      "         ...,\n",
      "         [-1.0198, -0.9252, -0.0329,  ..., -4.3648, -1.3759, -1.9862],\n",
      "         [ 1.1860,  0.0426,  1.2061,  ...,  1.7583,  1.3935,  0.4970],\n",
      "         [ 0.0264,  0.5305,  0.8274,  ...,  1.3045,  0.6640,  0.9124]],\n",
      "\n",
      "        [[ 1.7235,  0.9117,  1.9366,  ...,  1.5074, -0.0987, -0.0401],\n",
      "         [ 0.2166,  0.0433, -0.0113,  ...,  0.4868,  1.0641,  0.4058],\n",
      "         [-1.2219, -3.0964, -3.5738,  ...,  1.1532, -2.6787, -2.4315],\n",
      "         ...,\n",
      "         [-0.9036, -2.5291, -2.1030,  ..., -1.5619, -0.6384, -0.8196],\n",
      "         [ 2.1681,  0.1883,  1.2781,  ...,  0.5522,  0.8653,  1.0681],\n",
      "         [ 1.2011,  0.6345,  1.1944,  ...,  1.6963,  0.3467,  1.1721]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "import cached_conv as cc\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "cc.use_cached_conv(True)\n",
    "\n",
    "\n",
    "def WNConv1d(*args, **kwargs):\n",
    "    return weight_norm(nn.Conv1d(*args, **kwargs))\n",
    "\n",
    "def WNConv1dCached(*args, **kwargs):\n",
    "    return weight_norm(cc.Conv1d(*args, **kwargs))\n",
    "\n",
    "wn_conv1d = WNConv1d(5, 10, 7, padding=3)\n",
    "wn_conv1d_cached = WNConv1dCached(5, 10, 7, padding=3)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weight_g_data = torch.randn(10, 1, 1)\n",
    "weight_v_data = torch.randn(10, 5, 7)\n",
    "bias_data = torch.randn(10)\n",
    "wn_conv1d.weight_g.data = weight_g_data\n",
    "wn_conv1d.weight_v.data = weight_v_data\n",
    "wn_conv1d.bias.data = bias_data\n",
    "\n",
    "data = torch.randn(20, 5, 1000)\n",
    "\n",
    "t = benchmark.Timer(\n",
    "    stmt='wn_conv1d(data)',\n",
    "    globals={'wn_conv1d': wn_conv1d, 'data': data},\n",
    "    num_threads=1,\n",
    ")\n",
    "res = t.timeit(100)\n",
    "print(\"Non stream:\", res)\n",
    "out_nostream = wn_conv1d(data)\n",
    "\n",
    "wn_conv1d_cached.weight_g.data = weight_g_data\n",
    "wn_conv1d_cached.weight_v.data = weight_v_data\n",
    "wn_conv1d_cached.bias.data = bias_data\n",
    "\n",
    "t = benchmark.Timer(\n",
    "    stmt='wn_conv1d_cached(data)',\n",
    "    globals={'wn_conv1d_cached': wn_conv1d_cached, 'data': data},\n",
    "    num_threads=1,\n",
    ")\n",
    "res = t.timeit(100)\n",
    "print(\"Cached:\", res)\n",
    "out_cached = wn_conv1d_cached(data)\n",
    "\n",
    "print(torch.allclose(out_nostream[..., :-wn_conv1d_cached.cumulative_delay], out_cached[..., wn_conv1d_cached.cumulative_delay:], atol=1e-6))\n",
    "print(out_nostream[..., :-wn_conv1d_cached.cumulative_delay])\n",
    "print(out_cached[..., wn_conv1d_cached.cumulative_delay:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6]) torch.Size([1, 1, 6])\n",
      "tensor([[[-0.8099, -0.9363,  0.2203, -0.2220, -1.2132,  0.0279]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.9363,  0.2203, -0.2220, -1.2132,  0.0279, -0.5633]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.use_cached_conv(True)\n",
    "\n",
    "wn_conv1d = WNConv1d(1, 1, 3, padding=1)\n",
    "wn_conv1d_cached = WNConv1dCached(1, 1, 3, padding=cc.get_padding(3))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "data = torch.randn(1, 1, 6)\n",
    "\n",
    "weight_g_data = torch.randn(1, 1, 1)\n",
    "weight_v_data = torch.randn(1, 1, 3)\n",
    "bias_data = torch.randn(1)\n",
    "wn_conv1d.weight_g.data = weight_g_data\n",
    "wn_conv1d.weight_v.data = weight_v_data\n",
    "wn_conv1d.bias.data = bias_data\n",
    "\n",
    "wn_conv1d_cached.weight_g.data = weight_g_data\n",
    "wn_conv1d_cached.weight_v.data = weight_v_data\n",
    "wn_conv1d_cached.bias.data = bias_data\n",
    "\n",
    "chunk_size = 3\n",
    "res = []\n",
    "for i in range(0, data.shape[-1], chunk_size):\n",
    "    # Slice along the sequence dimension and apply conv1d to each chunk\n",
    "    tok = wn_conv1d_cached(data[..., i:i + chunk_size])\n",
    "    res.append(tok)\n",
    "\n",
    "# Concatenate all the chunks along the sequence dimension\n",
    "chunked_output = torch.cat(res, dim=-1)\n",
    "\n",
    "# Direct (non-chunked) computation for comparison\n",
    "non_chunked_output = wn_conv1d(data)\n",
    "\n",
    "print(chunked_output.shape, non_chunked_output.shape)\n",
    "print(chunked_output)\n",
    "print(non_chunked_output)\n",
    "\n",
    "wn_conv1d_cached.cumulative_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/audiotools/ml/layers/base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration with streaming:  11.978892087936401\n",
      "8\n",
      "torch.Size([1, 9, 992])\n",
      "=============================\n",
      "=============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/audiotools/ml/layers/base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration without streaming:  4.433102130889893\n",
      "torch.Size([1, 9, 992])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import dac\n",
    "\n",
    "# Monkey patching the DAC class to use cc.Conv1d instead of nn.Conv1d\n",
    "\n",
    "# Download a model\n",
    "model_path = dac.utils.download(model_type=\"44khz\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "dac.DAC.enable_streaming(True)\n",
    "model = dac.DAC.load(model_path).to(\"cpu\")\n",
    "delay = model.encoder_cumulative_delay\n",
    "\n",
    "torch.set_printoptions(precision=5, sci_mode=False)\n",
    "\n",
    "# set numpy random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load audio signal file\n",
    "silence = np.random.randn(*(1, 1, 512000)).astype(np.float32)\n",
    "data = torch.tensor(silence).to(\"cpu\")\n",
    "\n",
    "res = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    for i in range(0, data.shape[-1], 512):\n",
    "        # Slice along the sequence dimension and apply conv1d to each chunk\n",
    "        tok = model.encode(data[..., i:i + 512])[1]\n",
    "        res.append(tok)\n",
    "    end = time.time()\n",
    "\n",
    "# Concatenate all the chunks along the sequence dimension\n",
    "out = torch.cat(res, dim=-1)\n",
    "print(\"Duration with streaming: \", end - start)\n",
    "\n",
    "print(model.encoder_cumulative_delay)\n",
    "out = out[..., delay:]\n",
    "print(out.shape)\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"=============================\")\n",
    "\n",
    "\n",
    "dac.DAC.enable_streaming(False)\n",
    "model = dac.DAC.load(model_path).to(\"cpu\")\n",
    "\n",
    "# #print all model parameters\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.shape)\n",
    "\n",
    "# set numpy random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load audio signal file\n",
    "silence = np.random.randn(*(1, 1, 512000)).astype(np.float32)\n",
    "data = torch.tensor(silence).to(\"cpu\")\n",
    "\n",
    "start = time.time()\n",
    "out_nostream = model.encode(data)[1]\n",
    "end = time.time()\n",
    "\n",
    "print(\"Duration without streaming: \", end - start)\n",
    "out_nostream = out_nostream[..., :-delay]\n",
    "print(out_nostream.shape)\n",
    "\n",
    "print(torch.allclose(out[..., delay:-delay], out_nostream[..., delay:-delay], atol=1e-6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
