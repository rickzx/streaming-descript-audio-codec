{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[[ 0.2391,  0.2759,  0.8915,  ...,  2.2475,  1.3730,  2.1704],\n",
      "         [ 0.5690,  0.3283,  0.4935,  ...,  0.8048,  0.7730,  0.4228],\n",
      "         [-2.4467,  0.4928, -3.4065,  ..., -1.7856, -1.5958, -0.1326],\n",
      "         ...,\n",
      "         [-2.7717, -0.6683, -1.0477,  ..., -0.8070, -1.1878, -0.1473],\n",
      "         [ 0.9553,  0.9808,  0.7493,  ...,  0.8611,  1.7939,  1.8238],\n",
      "         [ 0.8837,  0.9023,  1.0396,  ...,  1.5872,  0.4577,  1.1960]],\n",
      "\n",
      "        [[ 0.7317,  2.8882,  1.5236,  ...,  3.4878,  4.8952,  0.2520],\n",
      "         [ 0.4875,  0.8073,  0.5325,  ...,  0.0925, -0.2831,  0.4675],\n",
      "         [-1.6555, -2.3700, -6.8651,  ..., -0.8240, -1.1611,  0.9850],\n",
      "         ...,\n",
      "         [-2.3175,  0.3974, -1.1541,  ..., -2.0387, -2.5608, -2.1537],\n",
      "         [ 0.1785,  0.1062,  0.9603,  ...,  1.4923,  0.2642,  1.1658],\n",
      "         [ 0.6244,  0.9748,  0.4891,  ...,  1.1547,  2.0384,  0.3623]],\n",
      "\n",
      "        [[ 1.5471,  2.3142, -0.0321,  ...,  3.3907,  1.0151,  1.6523],\n",
      "         [ 0.4586,  0.5339,  0.6181,  ...,  0.4847,  0.4774,  0.2738],\n",
      "         [ 0.5580, -4.5806, -4.2872,  ..., -0.5131, -1.7315, -2.7107],\n",
      "         ...,\n",
      "         [-1.8273, -0.8208, -2.4517,  ..., -0.5116, -1.3388, -0.9865],\n",
      "         [ 1.8638,  1.4054,  0.8197,  ...,  0.4049,  1.1175,  1.8428],\n",
      "         [ 1.2679,  0.9172,  0.3428,  ...,  1.0127,  0.9199,  0.7257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4303,  0.9407,  2.3502,  ...,  3.3942,  0.6659,  2.2038],\n",
      "         [ 0.8776,  0.6746,  0.8299,  ...,  0.5432,  0.0854,  0.9620],\n",
      "         [-1.5673, -2.2818, -1.1140,  ..., -0.3446, -3.4646,  2.6042],\n",
      "         ...,\n",
      "         [-0.9756,  0.7678, -1.0456,  ..., -1.2936, -1.6903, -0.6169],\n",
      "         [ 0.3488,  0.2618,  0.7301,  ...,  1.3557,  0.4638,  1.2840],\n",
      "         [ 1.2235,  0.1695,  1.3875,  ...,  1.1901,  0.7750,  0.7964]],\n",
      "\n",
      "        [[-0.4298,  3.1034,  0.5441,  ..., -1.2649,  0.4618,  1.4332],\n",
      "         [ 0.7998,  0.5493,  0.3957,  ...,  0.2120,  0.3455,  0.5838],\n",
      "         [-6.2248, -3.5599,  2.3173,  ...,  0.8402, -2.2254, -5.6610],\n",
      "         ...,\n",
      "         [-1.3530, -1.3505, -0.2200,  ..., -4.3648, -1.3759, -1.9862],\n",
      "         [ 0.5831,  0.0352,  1.0047,  ...,  1.7583,  1.3935,  0.4970],\n",
      "         [ 0.1642,  0.5625,  0.8667,  ...,  1.3045,  0.6640,  0.9124]],\n",
      "\n",
      "        [[ 1.1173, -0.5701,  2.2973,  ...,  1.5074, -0.0987, -0.0401],\n",
      "         [ 0.1803,  0.1208,  0.0668,  ...,  0.4868,  1.0641,  0.4058],\n",
      "         [-0.4448, -3.3007, -3.5659,  ...,  1.1532, -2.6787, -2.4315],\n",
      "         ...,\n",
      "         [-0.8209, -2.2548, -2.2953,  ..., -1.5619, -0.6384, -0.8196],\n",
      "         [ 1.5494,  0.4939,  0.9105,  ...,  0.5522,  0.8653,  1.0681],\n",
      "         [ 1.4491,  0.6100,  1.2613,  ...,  1.6963,  0.3467,  1.1721]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[[ 0.2391,  0.2759,  0.8915,  ...,  2.2475,  1.3730,  2.1704],\n",
      "         [ 0.5690,  0.3283,  0.4935,  ...,  0.8048,  0.7730,  0.4228],\n",
      "         [-2.4467,  0.4928, -3.4065,  ..., -1.7856, -1.5958, -0.1326],\n",
      "         ...,\n",
      "         [-2.7717, -0.6683, -1.0477,  ..., -0.8070, -1.1878, -0.1473],\n",
      "         [ 0.9553,  0.9808,  0.7493,  ...,  0.8611,  1.7939,  1.8238],\n",
      "         [ 0.8837,  0.9023,  1.0396,  ...,  1.5872,  0.4577,  1.1960]],\n",
      "\n",
      "        [[ 0.7317,  2.8882,  1.5236,  ...,  3.4878,  4.8952,  0.2520],\n",
      "         [ 0.4875,  0.8073,  0.5325,  ...,  0.0925, -0.2831,  0.4675],\n",
      "         [-1.6555, -2.3700, -6.8651,  ..., -0.8240, -1.1610,  0.9850],\n",
      "         ...,\n",
      "         [-2.3175,  0.3974, -1.1541,  ..., -2.0387, -2.5608, -2.1537],\n",
      "         [ 0.1785,  0.1062,  0.9603,  ...,  1.4923,  0.2642,  1.1658],\n",
      "         [ 0.6244,  0.9748,  0.4891,  ...,  1.1547,  2.0384,  0.3623]],\n",
      "\n",
      "        [[ 1.5471,  2.3142, -0.0321,  ...,  3.3907,  1.0151,  1.6523],\n",
      "         [ 0.4586,  0.5339,  0.6181,  ...,  0.4847,  0.4774,  0.2738],\n",
      "         [ 0.5580, -4.5806, -4.2872,  ..., -0.5131, -1.7315, -2.7107],\n",
      "         ...,\n",
      "         [-1.8273, -0.8208, -2.4517,  ..., -0.5116, -1.3388, -0.9865],\n",
      "         [ 1.8638,  1.4054,  0.8197,  ...,  0.4049,  1.1175,  1.8428],\n",
      "         [ 1.2679,  0.9172,  0.3428,  ...,  1.0127,  0.9199,  0.7257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4303,  0.9407,  2.3502,  ...,  3.3942,  0.6659,  2.2038],\n",
      "         [ 0.8776,  0.6746,  0.8299,  ...,  0.5432,  0.0854,  0.9620],\n",
      "         [-1.5673, -2.2818, -1.1140,  ..., -0.3446, -3.4646,  2.6042],\n",
      "         ...,\n",
      "         [-0.9756,  0.7678, -1.0456,  ..., -1.2936, -1.6903, -0.6169],\n",
      "         [ 0.3488,  0.2618,  0.7301,  ...,  1.3557,  0.4638,  1.2840],\n",
      "         [ 1.2235,  0.1695,  1.3875,  ...,  1.1901,  0.7750,  0.7964]],\n",
      "\n",
      "        [[-0.4298,  3.1034,  0.5441,  ..., -1.2649,  0.4618,  1.4332],\n",
      "         [ 0.7998,  0.5493,  0.3957,  ...,  0.2120,  0.3455,  0.5838],\n",
      "         [-6.2248, -3.5599,  2.3173,  ...,  0.8402, -2.2254, -5.6610],\n",
      "         ...,\n",
      "         [-1.3530, -1.3505, -0.2200,  ..., -4.3648, -1.3759, -1.9862],\n",
      "         [ 0.5831,  0.0352,  1.0047,  ...,  1.7583,  1.3935,  0.4970],\n",
      "         [ 0.1642,  0.5625,  0.8667,  ...,  1.3045,  0.6640,  0.9124]],\n",
      "\n",
      "        [[ 1.1173, -0.5701,  2.2973,  ...,  1.5074, -0.0987, -0.0401],\n",
      "         [ 0.1803,  0.1208,  0.0668,  ...,  0.4868,  1.0641,  0.4058],\n",
      "         [-0.4448, -3.3007, -3.5659,  ...,  1.1532, -2.6787, -2.4315],\n",
      "         ...,\n",
      "         [-0.8209, -2.2548, -2.2953,  ..., -1.5619, -0.6384, -0.8196],\n",
      "         [ 1.5494,  0.4939,  0.9105,  ...,  0.5522,  0.8653,  1.0681],\n",
      "         [ 1.4491,  0.6100,  1.2613,  ...,  1.6963,  0.3467,  1.1721]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "import cached_conv as cc\n",
    "\n",
    "cc.use_cached_conv(True)\n",
    "\n",
    "\n",
    "def WNConv1d(*args, **kwargs):\n",
    "    return weight_norm(nn.Conv1d(*args, **kwargs))\n",
    "\n",
    "def WNConv1dCached(*args, **kwargs):\n",
    "    return weight_norm(cc.Conv1d(*args, **kwargs))\n",
    "\n",
    "wn_conv1d = WNConv1d(5, 10, 7, padding=3)\n",
    "wn_conv1d_cached = WNConv1dCached(5, 10, 7, padding=3)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weight_g_data = torch.randn(10, 1, 1)\n",
    "weight_v_data = torch.randn(10, 5, 7)\n",
    "bias_data = torch.randn(10)\n",
    "wn_conv1d.weight_g.data = weight_g_data\n",
    "wn_conv1d.weight_v.data = weight_v_data\n",
    "wn_conv1d.bias.data = bias_data\n",
    "\n",
    "data = torch.randn(20, 5, 1000)\n",
    "out = wn_conv1d(data)\n",
    "\n",
    "wn_conv1d_cached.weight_g.data = weight_g_data\n",
    "wn_conv1d_cached.weight_v.data = weight_v_data\n",
    "wn_conv1d_cached.bias.data = bias_data\n",
    "\n",
    "out_cached = wn_conv1d_cached(data)\n",
    "\n",
    "print(torch.allclose(out[..., :-wn_conv1d_cached.cumulative_delay], out_cached[..., wn_conv1d_cached.cumulative_delay:], atol=1e-6))\n",
    "print(out[..., :-wn_conv1d_cached.cumulative_delay])\n",
    "print(out_cached[..., wn_conv1d_cached.cumulative_delay:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6]) torch.Size([1, 1, 6])\n",
      "tensor([[[-0.8099, -0.9363,  0.2203, -0.2220, -1.2132,  0.0279]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.9363,  0.2203, -0.2220, -1.2132,  0.0279, -0.5633]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.use_cached_conv(True)\n",
    "\n",
    "wn_conv1d = WNConv1d(1, 1, 3, padding=1)\n",
    "wn_conv1d_cached = WNConv1dCached(1, 1, 3, padding=cc.get_padding(3))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "data = torch.randn(1, 1, 6)\n",
    "\n",
    "weight_g_data = torch.randn(1, 1, 1)\n",
    "weight_v_data = torch.randn(1, 1, 3)\n",
    "bias_data = torch.randn(1)\n",
    "wn_conv1d.weight_g.data = weight_g_data\n",
    "wn_conv1d.weight_v.data = weight_v_data\n",
    "wn_conv1d.bias.data = bias_data\n",
    "\n",
    "wn_conv1d_cached.weight_g.data = weight_g_data\n",
    "wn_conv1d_cached.weight_v.data = weight_v_data\n",
    "wn_conv1d_cached.bias.data = bias_data\n",
    "\n",
    "chunk_size = 3\n",
    "res = []\n",
    "for i in range(0, data.shape[-1], chunk_size):\n",
    "    # Slice along the sequence dimension and apply conv1d to each chunk\n",
    "    tok = wn_conv1d_cached(data[..., i:i + chunk_size])\n",
    "    res.append(tok)\n",
    "\n",
    "# Concatenate all the chunks along the sequence dimension\n",
    "chunked_output = torch.cat(res, dim=-1)\n",
    "\n",
    "# Direct (non-chunked) computation for comparison\n",
    "non_chunked_output = wn_conv1d(data)\n",
    "\n",
    "print(chunked_output.shape, non_chunked_output.shape)\n",
    "print(chunked_output)\n",
    "print(non_chunked_output)\n",
    "\n",
    "wn_conv1d_cached.cumulative_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/audiotools/ml/layers/base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "/Users/cfruan/miniconda3/envs/mlc-audio/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "torch.Size([1, 1024, 92])\n",
      "tensor([[[  8.98867, -14.47900, -52.20496,  ...,   5.15977, -28.10490,\n",
      "           21.93532],\n",
      "         [ -4.08285,  84.29540, 104.61837,  ...,  25.47849,  59.95752,\n",
      "            1.54037],\n",
      "         [-40.37833, -17.11209, -24.56766,  ...,  23.47040, -51.99257,\n",
      "          -25.59319],\n",
      "         ...,\n",
      "         [-29.15557,  18.42965,  50.19261,  ..., -16.10726,  -0.41827,\n",
      "          -19.61252],\n",
      "         [ 43.76177, -21.42388,   0.79145,  ...,  -2.60167,  12.37717,\n",
      "           71.11745],\n",
      "         [-40.73623,  23.79416,  74.62721,  ..., -23.58209,  28.23978,\n",
      "          -25.59929]]], grad_fn=<SliceBackward0>)\n",
      "=============================\n",
      "=============================\n",
      "0\n",
      "torch.Size([1, 1024, 92])\n",
      "tensor([[[  8.98873, -14.47901, -52.20497,  ...,   5.15975, -28.10491,\n",
      "           21.93531],\n",
      "         [ -4.08285,  84.29539, 104.61831,  ...,  25.47848,  59.95754,\n",
      "            1.54039],\n",
      "         [-40.37836, -17.11202, -24.56760,  ...,  23.47041, -51.99262,\n",
      "          -25.59317],\n",
      "         ...,\n",
      "         [-29.15559,  18.42960,  50.19261,  ..., -16.10729,  -0.41824,\n",
      "          -19.61256],\n",
      "         [ 43.76181, -21.42396,   0.79145,  ...,  -2.60166,  12.37718,\n",
      "           71.11751],\n",
      "         [-40.73623,  23.79419,  74.62717,  ..., -23.58206,  28.23983,\n",
      "          -25.59926]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import dac\n",
    "\n",
    "# Monkey patching the DAC class to use cc.Conv1d instead of nn.Conv1d\n",
    "\n",
    "# Download a model\n",
    "model_path = dac.utils.download(model_type=\"44khz\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "dac.DAC.enable_streaming(True)\n",
    "model = dac.DAC.load(model_path).to(\"cpu\")\n",
    "delay = model.encoder_cumulative_delay\n",
    "\n",
    "torch.set_printoptions(precision=5, sci_mode=False)\n",
    "\n",
    "# set numpy random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load audio signal file\n",
    "silence = np.random.randn(*(1, 1, 51200)).astype(np.float32)\n",
    "data = torch.tensor(silence).to(\"cpu\")\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in range(0, data.shape[-1], 5120):\n",
    "    # Slice along the sequence dimension and apply conv1d to each chunk\n",
    "    tok = model.encode(data[..., i:i + 5120])\n",
    "    res.append(tok)\n",
    "\n",
    "# Concatenate all the chunks along the sequence dimension\n",
    "out = torch.cat(res, dim=-1)\n",
    "\n",
    "out = model.encode(data)\n",
    "print(model.encoder_cumulative_delay)\n",
    "out = out[..., delay:]\n",
    "print(out.shape)\n",
    "print(out[..., delay:-delay])\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"=============================\")\n",
    "\n",
    "\n",
    "dac.DAC.enable_streaming(False)\n",
    "model = dac.DAC.load(model_path).to(\"cpu\")\n",
    "\n",
    "# #print all model parameters\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.shape)\n",
    "\n",
    "# set numpy random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load audio signal file\n",
    "silence = np.random.randn(*(1, 1, 51200)).astype(np.float32)\n",
    "data = torch.tensor(silence).to(\"cpu\")\n",
    "\n",
    "out = model.encode(data)\n",
    "out = out[..., :-delay]\n",
    "print(model.encoder_cumulative_delay)\n",
    "print(out.shape)\n",
    "print(out[..., delay:-delay])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
